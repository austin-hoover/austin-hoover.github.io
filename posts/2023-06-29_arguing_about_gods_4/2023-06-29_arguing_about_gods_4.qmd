---
title: Fine-tuning arguments
date: 2023-06-29
author: Austin Hoover
categories: [teleological arguments, fine-tuning, multiverse]
bibliography: references.bib
csl: american-physics-society.csl
---

[In progress...]


Teleological arguments conclude that certain contingent features of the world are best explained by the existence of a designer (God). A classic argument of this form is "Paley's watch", which focuses on biological organisms. The contemporary debate revolves around cosmological fine-tuning. In this post, following Oppy, I assess several proposed explanations of fine-tuning: design, multiverse, necessity, chance, and brute contingency.


## 1. Paley's watch

Before discussing fine-tuning, it is worth visiting the classical biological design argument, starting with Paley's Watch:

> "In crossing a heath, suppose I pitched my foot against a stone, and were asked how the stone came to be there; I might possibly answer, that, for anything I knew to the contrary, it had lain there forever: nor would it perhaps be very easy to show the absurdity of this answer. But suppose I had found a watch upon the ground, and it should be inquired how the watch happened to be in that place; I should hardly think of the answer I had before given, that for anything I knew, the watch might have always been there. ... There must have existed, at some time, and at some place or other, an artificer or artificers, who formed [the watch] for the purpose which we find it actually to answer; who comprehended its construction, and designed its use. ... Every indication of contrivance, every manifestation of design, which existed in the watch, exists in the works of nature; with the difference, on the side of nature, of being greater or more, and that in a degree which exceeds all computation." [@Paley_1829]

Oppy suggests that Paley's inference to design stems from three observations: 

1. The watch has a principal function.
2. Various parts of the watch have functions.
3. The materials from which the parts are constructed are well suited to the functions that those parts have. 

Oppy suggests that Paley's inference to design relies instead on the background knowledge that watches are not produced naturally. But it is not clear that the inference works for biological systems, for which we do not have the same background knowledge. Additionally, evolutionary theory provides a plausible account of how nature could produce such systems.

A more recent argument focuses on "irreducibly complex" systems that would cease to function if any of their parts were removed. The claim is that it would be impossible for such a system to arise from gradual changes since the predecessor of any irreducibly complex system would have to be irreducibly complex. It seems to me that the proponent of this design argument will want to identify the first irreducibly complex system with the first biological system. A broader definition would include non-biological systems, but theories of physics and chemistry plausibly explain the complexity of such systems. A narrower definition would exclude some early life forms, but evolutionary theory provides a plausible natural link between simple and complex biological systems. On the other hand, it is unknown how biological systems developed from chemical systems. However, most think there is a natural link between chemistry and biology, and it would be difficult to show that such a link could not exist.

I feel that this argument does not address why God would design a self-organizing world in which the self-organization stops at the transition from chemistry to biology. It seems more elegant, and therefore more likely, that God would select laws and initial conditions such that life could develop without intervention.



## 2. Cosmic fine-tuning

The modern debate revolves around the *fine-tuning* of the universe for life, i.e., the extreme sensitivity of the development of life on physical parameters — laws, constants, and initial conditions. A comprehensive analysis of the fine-tuning data is found in [@Barnes_2012]. The SEP article on fine-tuning [@sep-fine-tuning] has a shorter list of apparently fine-tuned parameters which I repeat here.[^1]

[^1]: One might also consider the fine-tuning of physical laws — their functional form, not their parameters. This move opens a larger space of possible universes, and it is less clear how to identify the life-permitting region of this space. (There are obviously some requirements, such as the requirement of both repelling and attractive forces.) And, just as with the physical constants, it is unclear whether these laws could have been any different. Nonetheless, the theist might use laws in other types of teleological arguments; for example, something based on the "unreasonable effectiveness of mathematics" described by Wigner [@Wigner_1990] or the "nomological argument" recently raised by Hildebrand [@Hildebrand_2022].

* The strength of gravity relative to electromagnetism.
* The strength of the strong force relative to the electromagnetic force.
* The ratio of up quark mass to down quark mass.
* The strength of the weak force.
* The value of the cosmological constant.
* The energy density in the early universe.
* The fluctuation amplitudes in the early universe.
* The entropy of the early universe.[^2]

[^2]: One way to arrive at the low entropy of the early universe is the Past Hypothesis [@Albert_2001], which is proposed (as I understand it) as a way to justify our beliefs about the past. The problem comes from using classical statistical mechanics to retrodict prior states of the universe from the current state. To do this, one can imagine evolving the universe forward in time after reversing the velocity vector of every particle. In this picture, entropy will likely *increase* in the past —contrary to our memories. We must hypothesize that the initial state had a low entropy to justify our beliefs about the past and recover correct retrodictions from statistical mechanics. 
    The initial state's low entropy means that the initial state's probability would be small (basically zero) if drawn from a uniform distribution over the available state space. Penrose famously computed that the chances are one part in $10^{10^{123}}$. Some feel that the fine-tuning of the initial state requires a deeper explanation, while others do not [@sep-statphys-statmech; @sep-time-thermo; @Earman_2006; @Wallace_2016; @Wallace_2017; @Robinson_2023].

All these parameters are determined empirically rather than by the fundamental theories of physics. It is not obvious whether these parameters are fixed by necessity, so it makes some sense to ask what would happen if they were different. And it appears that these parameters are *just right* for life, i.e., the probability of life (or any complex structures) would be essentially zero if the parameters were drawn from a sufficiently wide uniform distribution.

There are important questions about how to interpret the fine-tuning data [@Oppy_2006_arguing]. 

1. The theories in question are incomplete; future theories may have no fine-tuned parameters. (This seems unlikely to me.) But we still need to deal with the fact that our present theories of physics work quite well to describe a wide range of phenomena, and all those theories (well, basically two theories) appear to be fine-tuned.
2. How should we assign probability distributions in the space of possible worlds? Should we assign a uniform distribution or something else?
3. What is the range that the various parameters can take? A finite range seems arbitrary, and there could be issues defining a uniform distribution over an infinite range (an infinite lottery). 
4. Are we exploring the multidimensional parameter space rather than varying one parameter at a time?

In other words, how did these parameters obtain their values? Were they randomly selected by some prehistoric mechanism? Were they intentionally selected by God? Are they fixed by necessity? Is there no deeper explanation for their values? Without an answer, we cannot say that the parameters are fine-tuned.

Although I worry about the issues above, I assign a moderate credence to the claim that the universe is fine-tuned for life. This seems to be the opinion of many physicists and philosophers. Thus, it makes sense to assume fine-tuning exists and work out its implications. 


## 3. Responses to fine-tuning

Some have argued that the evidence of fine-tuning ($E$) supports a hypothesis $H$: 
$$ 
\frac{Pr(H | E)}{Pr(\neg H | E)} = \frac{Pr(E | H)}{Pr(E | \neg H)}\frac{Pr(H)}{Pr(\neg H)} > 1,
$$ 

We can map the candidate hypotheses to the following responses to an all-sixes configuration of one billion dice.

1. *Many rolls*: There were probably many prior rolls.
2. *Many tables*: There were probably many simultaneous rolls.
3. *Intentional agent*: An intentional agent arranged The dice in the all-sixes configuration.
4. *One roll*: The dice were rolled once. The all-sixes configuration was unlikely, but unlikely events do not necessarily require explanations.
5. *Brute contingency*: The dice could have landed in a different configuration, but no explanation is needed for the observed configuration.
6. *Necessity*: The dice could not have landed in a different configuration.

Here, the all-sixes configuration is analogous to a life-supporting universe. Response 2 corresponds to the *multiverse hypothesis*: that there are many universes, each with different laws and initial conditions. Response 3 corresponds to the *design hypothesis*: that an intentional agent selected the laws and initial conditions of the universe. Response 4 corresponds to the claim that the laws and initial conditions were unlikely (in some sense), but that unlikely events do not necessarily require explanations; the selection process, even if random, provides a sufficient explanation. Response 5 corresponds to the claim that although the laws and initial conditions could have been different, they do not require a deeper explanation. Response 6 corresponds to the claim that the laws and initial conditions are fixed by metaphysical necessity. 

```{mermaid}
%%| echo: false
%%| fig-width: 585px
%%| fig-align: center
flowchart TB
  A[Evidence of fine-tuning] 
  A --> B[Accept]
      B --> D[Explanation needed]
          D --> F[Design]
          D --> G[Multiverse]
          D --> H[Chance]
      B --> E[No explanation needed]
          E --> I[Brute contingency]
          E --> J[Necessity]
  A --> C[Reject]
```
<br>


### 3.2. The many-worlds explanation

The multiverse explanation is an elegant solution to the fine-tuning problem, at least on its face. If there were many universes with different parameters, then it would be unsurprising to find *some* life-supporting universes. Observers would be guaranteed to find themselves in such a universe. Objections to the multiverse include the Inverse Gambler's Fallacy, the This-Universe Objection, and the Incoherence Objection. Let's take these in turn.

#### 3.2.1. Inverse gambling
#### 3.2.2. This universe
#### 3.2.3. Incoherence


### 3.3. The theistic explanation

#### 3.3.1. What would God create?
#### 3.3.2. Why would God create a fine-tuned universe?
#### 3.3.3. Would God create a multiverse?

### 3.4. No explanation
#### 3.4.1. Brute contingency
#### 3.4.2. Metaphysical necessity


## 4. Conclusion


## 5. Plans

Before moving on to arguments from evil, I plan to spend more time on teleological and cosmological arguments. In particular, I plan to spend some time on [the nomological argument]( https://onlinelibrary.wiley.com/doi/abs/10.1111/nous.12364),  [psychophysical harmony](https://philarchive.org/rec/CUTPHA), and [the unreasonable effectiveness of mathematics](https://www.tandfonline.com/doi/abs/10.1080/14746700.2011.547001). These are all related to the fine-tuning argument. I also have not covered the [Thomistic cosmological argument]() defended by Edward Feser. Or I may skip to arguments from evil and come back to these at some point.