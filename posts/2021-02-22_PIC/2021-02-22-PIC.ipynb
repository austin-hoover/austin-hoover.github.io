{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Particle-in-cell simulation\"\n",
    "author: Austin Hoover\n",
    "date: '2022-02-22'\n",
    "description: \"An introduction to electrostatic particle-in-cell solvers.\"\n",
    "image: potential_fft.png\n",
    "number-sections: false\n",
    "categories: [electrodynamics, space charge, particle accelerators]\n",
    "bibliography: references.bib\n",
    "csl: american-physics-society.csl\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <br> -->\n",
    "Many codes exist for beam physics simulations (one example is [PyORBIT](https://github.com/PyORBIT-Collaboration/py-orbit)). A key component of the these simulations is the inclusion of the electromagnetic interactions between particles in the beam, also known as *space charge* forces. One way to compute space charge forces is the particle-in-cell (PIC) method. This post implements a basic version of the PIC method in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use *bunch* to refer to a group of particles in three-dimensional (3D) space, and we'll use a local cartesian coordinate system whose origin moves with the center of the bunch as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 1. Coordinate system defined in the beam rest frame.](coordinate_system.png){width=55%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $s$ coordinate specifies the position of the bunch in the accelerator, and the path can be curved. Now for a few assumptions and approximations. First, assume all particles in the bunch move at a constant velocity $\\beta c$, where $c$ is the speed of light. We then make the *paraxial approximation*. It's conventional to use the slope $x' = dx/ds$ instead of the velocity, and the paraxial approximation assumes this slope is very small. Usually we report this slope in milliradians since $tan\\theta \\approx \\theta$ for small angles. Next we assume that the transverse ($x$-$y$) size of the bunch varies slowly along the $s$ axis. If this is true and we look at the electric field in a transverse slice of the bunch, there won't be much difference between the true field and the field of an infinitely long, uniform density cylinder. Our focus will be on the transverse dynamics of such a slice, so we'll treat each \"particle\" as an infinite line of charge. The figure below illustrates this approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 2. Coasting beam approximation. (Source: G. Franchetti, *Space charge in circular machines*, CERN Accelerator School Proceedings (2017). [https://e-publishing.cern.ch/index.php/CYRSP/article/view/413](https://e-publishing.cern.ch/index.php/CYRSP/article/view/413))](coasting_beam.png){width=70%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approximation is to neglect any magnetic fields generated by the beam, which is again valid if the transverse velocities are very small relative to $\\beta c$. All this being said, the equations of motion without any external forces, i.e., in free space, can be written as \n",
    "\n",
    "$$ \n",
    "\\mathbf{x}'' = \\frac{q}{mc^2\\beta^2\\gamma^3} \\mathbf{E},\n",
    "$${#eq-EOM}\n",
    "\n",
    "where $\\mathbf{x} = [x, y]^T$ is the coordinate vector, $\\mathbf{E} = [E_x, E_y]^T$ is the self-generated electric field, $m$ is the particle mass, and $\\gamma = \\left({1 - \\beta^2}\\right)^{-1/2}$. Let's first address the factor $\\gamma^{-3}$ in the equation of motion, which means that the space charge force goes to zero as the velocity approaches the speed of light. This is because parallel moving charges generate an attractive magnetic force which grows with velocity, completely cancelling the electric force in the limit $v \\rightarrow c$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 3. The magnetic force between parallel currents is attractive. (Source: OpenStax University Physics.)](parallel_currents.jpg){width=50%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may ask: what about the rest frame in which there is no magnetic field? But special relativity says that electrogmagnetic fields change with reference frame. Using the transformations defined [here](https://en.wikipedia.org/wiki/Classical_electromagnetism_and_special_relativity), you can quickly prove that \n",
    "\n",
    "$$\n",
    "\\mathbf{E}_{lab} = \\frac{\\mathbf{E}_{rest}}{\\gamma}.\n",
    "$${#eq-Lorentz}\n",
    "\n",
    "This inverse relationship between velocity and the space charge force has real-life consequences. It tells us that space charge is important if 1) the beam is very intense, meaning there are many particles in a small area, or 2) the beam is very energetic, meaning it is moving extremely fast. For example, space charge can usually be ignored in electron beams, which move near the speed of light for very modest energies due to their tiny mass, but is significant in high-intensity, low-energy hadron accelerators such as [FRIB](https://frib.msu.edu), [SNS](https://neutrons.ornl.gov/sns), and [ESS](https://europeanspallationsource.se)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now address the difficulty in determining the evolution of this system: the force on a particle in an $n$-particle bunch depends on the positions of the other $n - 1$ particles. The approach of statistical mechanics to this problem is to introduce a *distribution function* $f(\\mathbf{x}, \\mathbf{x}', s)$ which gives the particle density at axial position $s$ and phase space coordinates $\\mathbf{x}$, $\\mathbf{x}'$. The Vlasov-Poisson system of equations determines the evolution of $f$ as long as we ignore collisions between particles:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{f}}{\\partial{s}} + \n",
    "\\mathbf{x}'\\cdot \\frac{\\partial{f}}{\\partial{\\mathbf{x}}} + \n",
    "\\mathbf{x}'' \\cdot \\frac{\\partial{f}}{\\partial{\\mathbf{x}'}} \n",
    "= 0.\n",
    "$${#eq-Vlasov}\n",
    "\n",
    "We know $\\mathbf{x''}$ from @eq-EOM. The electric field is obtained from Poisson's equation:\n",
    "\n",
    "$$ \n",
    "\\nabla \\cdot \\mathbf{E} = -\\nabla^2 \\phi = \\frac{\\rho}{\\varepsilon_0}.\n",
    "$${#eq-Poisson}\n",
    "\n",
    "Finally, the transverse charge density $\\rho$ is determined by\n",
    "\n",
    "$$\n",
    "\\rho = q \\int{f dx'dy'}.\n",
    "$${#eq-rho}\n",
    "\n",
    "Although these equations are easy to write down, they are generally impossible to solve analytically. We need to turn to a computer for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vlasov equation could be solved directly, but this is difficult, especially in 2D or 3D. On the other end of the spectrum, the notion of a fluid in phase space could be abandoned and each particle could be tracked individually, computing the forces using direct sums. But this is infeasible with current hardware; the time complexity would by $O(n^2)$, where $n$ is the number of particles, and $n$ may be on the order of $10^{14}$. The particle-in-cell (PIC) method is a sort of combination of these two approaches. The idea is to track a group of *macroparticles* according to @eq-EOM, each of which represents a large number of real particles. The fields, however, are solved from @eq-Poisson. The key step is transforming back and forth between a discrete and continuous representation of the bunch. The simulation loop for the PIC method is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 4. The particle-in-cell (PIC) loop.](pic_loop.png){width=77%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections I will discuss each of these steps and implement them in Python. The hidden cell below shows all the imports needed to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| code-summary: \"Imports\"\n",
    "import Cython\n",
    "%load_ext cython\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Ellipse\n",
    "import proplot as pplt\n",
    "from scipy.fft import fft2\n",
    "from scipy.fft import ifft2\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.integrate import odeint\n",
    "from scipy.stats import truncnorm\n",
    "import seaborn as sns \n",
    "from tqdm.notebook import trange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "pplt.rc['animation.html'] = 'jshtml'\n",
    "pplt.rc['axes.grid'] = False\n",
    "pplt.rc['cmap.discrete'] = False\n",
    "pplt.rc['cmap.sequential'] = 'viridis'\n",
    "pplt.rc['figure.facecolor'] = 'white'\n",
    "pplt.rc['savefig.dpi'] = 'figure'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a `Bunch` class, which is a simple container for the bunch coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "class Bunch:\n",
    "    \"\"\"Container for four-dimensional phase space distribution.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    intensity : float\n",
    "        Number of physical particles in the bunch.\n",
    "    length : float\n",
    "        Length of the bunch [m].\n",
    "    mass, kin_energy : float\n",
    "        Mass [GeV/c^2], charge [C], and kinetic energy [GeV] per particle.\n",
    "    nparts : float\n",
    "        Number of macroparticles in the bunch.\n",
    "    X : ndarray, shape (nparts, 4)\n",
    "        Array of particle coordinates. Columns are [x, x', y, y']. Units are\n",
    "        meters and radians.\n",
    "    positions : ndarray, shape (nparts, 2):\n",
    "        Just the x and y positions (for convenience).\n",
    "    \"\"\"\n",
    "    def __init__(self, intensity=1e14, length=250., mass=0.938, kin_energy=1.0):\n",
    "        self.intensity, self.length = intensity, length\n",
    "        self.mass, self.kin_energy = mass, kin_energy\n",
    "        self.gamma = 1 + (kin_energy / mass) # Lorentz factor\n",
    "        self.beta = np.sqrt(1 - (1 / self.gamma)**2) # v/c\n",
    "        r0 = 1.53469e-18 # classical proton radius [m]\n",
    "        self.perveance = 2 * r0 * intensity / (length * self.beta**2 * self.gamma**3)\n",
    "        self.nparts = 0\n",
    "        self.compute_macrosize()\n",
    "        self.X, self.positions = None, None\n",
    "        \n",
    "    def compute_macrosize(self):\n",
    "        \"\"\"Update the macrosize and macrocharge.\"\"\"\n",
    "        self.macrosize = self.intensity // self.nparts if self.nparts > 0 else 0\n",
    "                                \n",
    "    def fill(self, X):\n",
    "        \"\"\"Fill with particles. X is the 4D phase space coordinate array.\"\"\"\n",
    "        self.X = X if self.X is None else np.vstack([self.X, X])\n",
    "        self.positions = self.X[:, [0, 2]]\n",
    "        self.nparts = self.X.shape[0]\n",
    "        self.compute_macrosize()\n",
    "\n",
    "    def compute_extremum(self):\n",
    "        \"\"\"Get extreme x and y coorinates.\"\"\"\n",
    "        self.xmin, self.ymin = np.min(self.positions, axis=0)\n",
    "        self.xmax, self.ymax = np.max(self.positions, axis=0)\n",
    "        self.xlim, self.ylim = (self.xmin, self.xmax), (self.ymin, self.ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from a group of macroparticles, we need to produce a charge density $\\rho_{i,j}$ on a grid. The most simple approach is the *nearest grid point (NGP)* method, which, as the name suggests, assigns the full particle charge to the closest grid point. This is commonly called *zero-order weighting*; although it is very fast and easy to implement, it is not commonly used because it can lead to significant noise. A better method called *cloud-in-cell (CIC)* treats each particle as a rectangular, uniform density cloud of charge with dimensions equal to the grid spacing. A fractional part of the charge is assigned based on the fraction of the cloud overlapping with a given cell. This can be thought of as *first-order weighting*. To get a sense of what these methods are doing (in 1D), we can slide a particle across a cell and plot the resulting density of the cell at each position, thus giving an effective particle shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "def shape_func(u, v, cell_width, method='NGP'):\n",
    "    S, diff = 0.0, np.abs(u - v)\n",
    "    if method.upper() == 'NGP':\n",
    "        S = 1.0 if diff < (0.5 * cell_width) else 0.0\n",
    "    elif method.upper() == 'CIC':\n",
    "        S = 1.0 - diff / cell_width if diff < cell_width else 0.0\n",
    "    return S / cell_width\n",
    "    \n",
    "fig, ax = pplt.subplots(figsize=(4.0, 1.5))\n",
    "xvals = np.linspace(-1.0, 1.0, 1000)\n",
    "for i, method in enumerate(['NGP', 'CIC']):\n",
    "    densities = [shape_func(x, 0.0, 1.0, method) for x in xvals]\n",
    "    ax.plot(xvals, densities, color='black', ls=['-', ':'][i], label=method,)\n",
    "ax.format(ylim=(0.0, 1.1), xlabel='($x - x_k) \\,/\\, \\Delta x$', ylabel='Density')\n",
    "ax.legend(loc='r', ncols=1, framealpha=0.0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "fig.save('./_output_NGP_CIC.png', dpi=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 5. Effective particle shape for Nearest-grid-point (NGP) and cloud-in-cell (CIC) weighting.](./_output_NGP_CIC.png){width=55%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NGP method leads to a discontinuous boundary while the CIC method leads to a continous boundary (but discontinous derivative). There are also higher order methods which lead to a smooth boundary, but I don't cover those here. \n",
    "\n",
    "We also need to perform the inverse operation: given the electric field at each grid point, interpolate the value at each particle position. The same method applies here. NGP just uses the electric field at the nearest grid point, while CIC weights the four nearest grid points. The following `Grid` class implements the CIC method. Notice that [Cython](https://cython.readthedocs.io/en/latest/src/userguide/numpy_tutorial.html) is used in the for-loop in the `distribute` method. I couldn't figure out a way to perform this operation with the loop, and in pure Python it took about 90% of the runtime for a single simulation step. Using Cython gave a significant performance boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "class Grid:\n",
    "    \"\"\"Class for 2D grid.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    xmin, ymin, xmax, ymax : float\n",
    "        Minimum and maximum coordinates.\n",
    "    Nx, Ny : int\n",
    "        Number of grid points.\n",
    "    dx, dy : int\n",
    "        Spacing between grid points.\n",
    "    x, y : ndarray, shape (Nx,) or (Ny,)\n",
    "        Positions of each grid point.\n",
    "    cell_area : float\n",
    "        Area of each cell.\n",
    "    \"\"\"\n",
    "    def __init__(self, xlim=(-1.0, 1.0), ylim=(-1.0, 1.0), size=(64, 64)):\n",
    "        self.xlim = xlim\n",
    "        self.ylim = ylim\n",
    "        (self.xmin, self.xmax) = self.xlim\n",
    "        (self.ymin, self.ymax) = self.ylim\n",
    "        self.size = size\n",
    "        (self.Nx, self.Ny) = size\n",
    "        self.dx = (self.xmax - self.xmin) / float(self.Nx - 1)\n",
    "        self.dy = (self.ymax - self.ymin) / float(self.Ny - 1)\n",
    "        self.cell_area = self.dx * self.dy\n",
    "        self.x = np.linspace(self.xmin, self.xmax, self.Nx)\n",
    "        self.y = np.linspace(self.ymin, self.ymax, self.Ny)\n",
    "        \n",
    "    def set_lims(self, xlim, ylim):\n",
    "        \"\"\"Set the min and max grid coordinates.\"\"\"\n",
    "        self.__init__(xlim=xlim, ylim=ylim, size=self.size)\n",
    "        \n",
    "    def zeros(self):\n",
    "        \"\"\"Create array of zeros with same size as the grid.\"\"\"\n",
    "        return np.zeros((self.size))\n",
    "\n",
    "    def distribute(self, positions):\n",
    "        \"\"\"Distribute points on the grid using the cloud-in-cell (CIC) method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        positions : ndarray, shape (n, 2)\n",
    "            List of (x, y) positions.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        rho : ndarray, shape (Nx, Ny)\n",
    "            The value rho[i, j] gives the number of macroparticles in the i,j cell.\n",
    "        \"\"\"\n",
    "        # Compute area overlapping with 4 nearest neighbors (A1, A2, A3, A4)\n",
    "        ivals = np.floor((positions[:, 0] - self.xmin) / self.dx).astype(int)\n",
    "        jvals = np.floor((positions[:, 1] - self.ymin) / self.dy).astype(int)\n",
    "        ivals[ivals > self.Nx - 2] = self.Nx - 2\n",
    "        jvals[jvals > self.Ny - 2] = self.Ny - 2\n",
    "        x_i, x_ip1 = self.x[ivals], self.x[ivals + 1]\n",
    "        y_j, y_jp1 = self.y[jvals], self.y[jvals + 1]\n",
    "        _A1 = (positions[:, 0] - x_i) * (positions[:, 1] - y_j)\n",
    "        _A2 = (x_ip1 - positions[:, 0]) * (positions[:, 1] - y_j)\n",
    "        _A3 = (positions[:, 0] - x_i) * (y_jp1 - positions[:, 1])\n",
    "        _A4 = (x_ip1 - positions[:, 0]) * (y_jp1 - positions[:, 1])\n",
    "        # Distribute fractional areas\n",
    "        rho = self.zeros()\n",
    "        cdef double[:, :] rho_view = rho \n",
    "        cdef int i, j\n",
    "        for i, j, A1, A2, A3, A4 in zip(ivals, jvals, _A1, _A2, _A3, _A4):\n",
    "            rho_view[i, j] += A4\n",
    "            rho_view[i + 1, j] += A3\n",
    "            rho_view[i, j + 1] += A2\n",
    "            rho_view[i + 1, j + 1] += A1      \n",
    "        return rho / self.cell_area\n",
    "\n",
    "    def interpolate(self, grid_vals, positions):\n",
    "        \"\"\"Interpolate values from the grid using the CIC method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        positions : ndarray, shape (n, 2)\n",
    "            List of (x, y) positions.\n",
    "        grid_vals : ndarray, shape (n, 2)\n",
    "            Scalar value at each coordinate point.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        int_vals : ndarray, shape (nparts,)\n",
    "            Interpolated value at each position.\n",
    "        \"\"\"\n",
    "        int_func = RegularGridInterpolator((self.x, self.y), grid_vals)\n",
    "        return int_func(positions)\n",
    "\n",
    "    def gradient(self, grid_vals):\n",
    "        \"\"\"Compute gradient using 2nd order centered differencing.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        grid_vals : ndarray, shape (Nx, Ny)\n",
    "            Scalar values at each grid point.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        gradx, grady : ndarray, shape (Nx, Ny)\n",
    "            The x and y gradient at each grid point.\n",
    "        \"\"\"\n",
    "        return np.gradient(grid_vals, self.dx, self.dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should also be mentioned that the field interpolation method should be the same as the charge deposition method; if this is not true, it is possible for a particle to exert a force on itself! Let's test the method with a $64 \\times 64$ grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: True\n",
    "#| code-fold: True\n",
    "#| fig-cap: \"Fig. 6. Test of cloud-in-cell (CIC) particle weighting on a regular 64 x 64 grid.\"\n",
    "# Create a 2D bunch.\n",
    "np.random.seed(1)\n",
    "n_parts = 100000\n",
    "_X = np.random.normal(scale=1.0, size=(n_parts, 2))\n",
    "n_clusters = 4\n",
    "for _ in range(n_clusters):\n",
    "    loc = np.random.uniform(-2.0, 2.0, size=2)\n",
    "    scale = np.random.uniform(0.5, 1.5, size=2)\n",
    "    _X = np.vstack([_X, np.random.normal(loc=loc, scale=scale, size=(n_parts, 2))])\n",
    "    \n",
    "_X = _X - np.mean(_X)\n",
    "idx, = np.where(np.sqrt(_X[:, 0]**2 + _X[:, 1]**2) < 5.0)\n",
    "_X = _X[idx, :]\n",
    "_X = _X - np.mean(_X)\n",
    "\n",
    "X = np.zeros((_X.shape[0], 4))\n",
    "X[:, (0, 2)] = _X\n",
    "\n",
    "bunch = Bunch()\n",
    "bunch.fill(X)\n",
    "bunch.compute_extremum()\n",
    "\n",
    "# Distribute the particles on an x-y grid.\n",
    "n_bins = 64\n",
    "grid = Grid(bunch.xlim, bunch.ylim, size=(n_bins, n_bins))\n",
    "rho = grid.distribute(bunch.positions) \n",
    "\n",
    "# Plot\n",
    "fig, axs = pplt.subplots(ncols=2, figwidth=7)\n",
    "axs[0].format(title=f'{n_samp} random samples')\n",
    "axs[1].format(title='CIC weighting');\n",
    "axs.format(xlabel='x [mm]', ylabel='y [mm]')\n",
    "\n",
    "n_samp = 2000\n",
    "idx = np.random.choice(X.shape[0], n_samp, replace=False)\n",
    "X_samp = X[idx, :]\n",
    "axs[0].scatter(X_samp[:, 0], X_samp[:, 2], s=1, c='w', ec='None')\n",
    "axs[0].set_facecolor('k')\n",
    "axs[1].pcolormesh(grid.x, grid.y, rho.T, cmap='mono_r')\n",
    "axs.format(xlim=grid.xlim, ylim=grid.ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field solver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workhorse in the simulation loop is the field solver. We need to solve Poisson's equation:\n",
    "\n",
    "$$\n",
    "\\left({\\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}}\\right) = -\\frac{\\rho\\left(x, y\\right)}{\\varepsilon_0}.\n",
    "$${#eq-label}\n",
    "\n",
    "The discretized version of the equation reads\n",
    "\n",
    "$$ \n",
    "\\frac{\\phi_{i+1,j} -2\\phi_{i,j} +\\phi_{i-1,j}}{{\\Delta_x}^2} + \\frac{\\phi_{i,j+1} -2\\phi_{i,j} + \\phi_{i,j-1}}{{\\Delta_y}^2} = -\\frac{\\rho_{i,j}}{\\varepsilon_0}\n",
    "$${#eq-label}\n",
    "\n",
    "for a grid with spacing $\\Delta_x$ and $\\Delta_y$. There are multiple paths to a solution; we will focus on the method implemented in PyORBIT which utilizes the Fourier convolution theorem. Let's briefly go over this method. The potential from an infinite line of elementary charges at the origin with number density $\\lambda$ is \n",
    "\n",
    "$$ \n",
    "\\phi(\\mathbf{x}) = -\\frac{\\lambda e}{2\\pi\\varepsilon_0} \\ln{|\\mathbf{x}|} = -\\frac{\\lambda e}{2\\pi\\varepsilon_0} \\int{\\ln{|\\mathbf{x} - \\mathbf{y}|}\\delta(\\mathbf{y})d\\mathbf{y}}.\n",
    "$${#eq-label}\n",
    "\n",
    "Note that $\\mathbf{y}$ is just a dummy variable. By letting $G(\\mathbf{x} - \\mathbf{y}) = -\\ln{|\\mathbf{x} - \\mathbf{y}|}$ and $\\rho(\\mathbf{x}) = \\delta(\\mathbf{x})$, then up to a scaling factor we have\n",
    "\n",
    "$$ \n",
    "\\phi(\\mathbf{x}) = \\int{G(\\mathbf{x} - \\mathbf{y})\\rho(\\mathbf{y})d\\mathbf{y}} = G(\\mathbf{x}) * \\rho(\\mathbf{x}). \n",
    "$${#eq-label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this form the potential is a [convolution](https://en.wikipedia.org/wiki/Convolution) (represented by $*$) of the charge density $\\rho$ with $G$, which is called the [Green's function](https://en.wikipedia.org/wiki/Green%27s_function). On the grid this will look like\n",
    "\n",
    "$$\n",
    "\\phi_{i, j} = \\sum_{k,l \\ne i,j}{G_{i-k, j-l} \\rho_{k, l}}.\n",
    "$${#eq-Poisson_Green}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solves the problem in $O(N^2)$ time complexity for $N$ grid points. This is already much faster than a direct force calculation but could still get expensive for fine grids. We can speed things up by exploiting the [convolution theorem](https://en.wikipedia.org/wiki/Convolution_theorem), which says that the Fourier transform of a convolution of two functions is equal to the product of their Fourier transforms. The Fourier transform is defined by\n",
    "\n",
    "$$\n",
    "\\hat{\\phi}(\\mathbf{k})= \\mathcal{F}\\left[\\phi(\\mathbf{x})\\right] = \\int_{-\\infty}^{\\infty}{e^{-i\\mathbf{k}\\cdot\\mathbf{x}} \\phi(\\mathbf{x}) d\\mathbf{x}}.\n",
    "$${#eq-label}\n",
    "\n",
    "The convolution theorem then says\n",
    "$$\n",
    "\\mathcal{F}\\left[\\rho * G\\right] = \\mathcal{F}\\left[\\rho\\right] \\cdot \\mathcal{F}\\left[G\\right].\n",
    "$${#eq-label}\n",
    "\n",
    "For the discrete equation this gives\n",
    "\n",
    "$$\n",
    "\\hat{\\phi}_{n, m} = \\hat{\\rho}_{n, m} \\hat{G}_{n, m},\n",
    "$${#eq-label}\n",
    "\n",
    "where the hat represents the discrete Fourier transform. The time complexity can be reduced to $O\\left(N \\log N\\right)$ with the [FFT](https://en.wikipedia.org/wiki/Fast_Fourier_transform) algorithm at our disposal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a caveat to this method: @eq-Poisson_Green must be a circular convolution in order to use the FFT algorithm, which means $G$ must be periodic. But the beam is in free space (we've neglected any conducting boundary), so this is not true. We can make it true by doubling the grid size in each dimension. We then make $G$ a mirror reflection in the new quadrants so that it is periodic, and also set the charge density equal to zero in these regions. After running the method on this larger grid, the potential in the new quadrants will be unphysical; however, the potential in the original quadrant will be correct. There are also some tricks we can play to reduce the space complexity, and in the end doubling the grid size is not much of a price to pay for the gain in speed. The method is implemented in the `PoissonSolver` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonSolver:\n",
    "    \"\"\"Class to solve Poisson's equation on a 2D grid.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    rho, phi, G : ndarray, shape (2*Nx, 2*Ny)\n",
    "        The density (rho), potential (phi), and Green's function (G) at each\n",
    "        grid point on a doubled grid. Only one quadrant (i < Nx, j < Ny)\n",
    "        corresponds to to the real potential.\n",
    "    \"\"\"\n",
    "    def __init__(self, grid, sign=-1.0):\n",
    "        self.grid = grid\n",
    "        new_shape = (2 * self.grid.Nx, 2 * self.grid.Ny)\n",
    "        self.rho = np.zeros(new_shape)\n",
    "        self.G = np.zeros(new_shape)\n",
    "        self.phi = np.zeros(new_shape)\n",
    "        \n",
    "    def set_grid(self, grid):\n",
    "        self.__init__(grid)\n",
    "        \n",
    "    def compute_greens_function(self):\n",
    "        \"\"\"Compute Green's function on doubled grid.\"\"\"\n",
    "        Nx, Ny = self.grid.Nx, self.grid.Ny\n",
    "        Y, X = np.meshgrid(self.grid.x - self.grid.xmin, self.grid.y - self.grid.ymin)\n",
    "        self.G[:Nx, :Ny] = -0.5 * np.log(X**2 + Y**2, out=np.zeros_like(X), \n",
    "                                         where=(X + Y > 0))\n",
    "        self.G[Nx:, :] = np.flip(self.G[:Nx, :], axis=0)\n",
    "        self.G[:, Ny:] = np.flip(self.G[:, :Ny], axis=1)\n",
    "                \n",
    "    def get_potential(self, rho):\n",
    "        \"\"\"Compute the scaled electric potential on the grid.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        rho : ndarray, shape (Nx, Ny)\n",
    "            Number of macroparticles at each grid point.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        phi : ndarray, shape (Nx, Ny)\n",
    "            Scaled electric potential at each grid point.\n",
    "        \"\"\"\n",
    "        Nx, Ny = self.grid.Nx, self.grid.Ny\n",
    "        self.rho[:Nx, :Ny] = rho\n",
    "        self.compute_greens_function()\n",
    "        self.phi = ifft2(fft2(self.G) * fft2(self.rho)).real\n",
    "        return self.phi[:Nx, :Ny]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the algorithm gives the following potential on the doubled grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| fig-cap: \"Fig. 7. Electric potential on doubled grid.\"\n",
    "solver = PoissonSolver(grid)\n",
    "phi = solver.get_potential(rho)\n",
    "\n",
    "fig, axs = pplt.subplots(ncols=2, figwidth=8.0, share=False, space=5)\n",
    "axs[0].pcolormesh(solver.rho.T, cmap='mono_r')\n",
    "axs[1].pcolormesh(solver.phi.T, cmap='mono_r')\n",
    "for ax in axs:\n",
    "    ax.axvline(grid.Nx - 0.5, c='w')\n",
    "    ax.axhline(grid.Ny - 0.5, c='w')\n",
    "    for xy in [(0.65, 0.75), (0.15, 0.75), (0.65, 0.25)]:\n",
    "        ax.annotate('unphysical', xy=xy, xycoords='axes fraction', c='w')\n",
    "axs[0].format(title=r'Density $\\rho$')\n",
    "axs[1].format(title=r'Potential $\\phi$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then approximate the gradient of the potential using second-order centered differencing. This gives\n",
    "\n",
    "$$(\\nabla\\phi)_{i,j} = \\frac{\\phi_{i+1,j} - \\phi_{i-1,j}}{2\\Delta_x} \\hat{x} + \\frac{\\phi_{i,j+1} - \\phi_{i,j-1}}{2\\Delta_y} \\hat{y}. \\tag{15}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the electric field at each position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| fig-cap: \"Fig. 8. Electric field on original grid.\"\n",
    "Ex, Ey = grid.gradient(-phi)\n",
    "\n",
    "fig, axs = pplt.subplots(ncols=2, figwidth=7.5, sharey=True)\n",
    "for ax, E in zip(axs, [Ex, Ey]):\n",
    "    m = ax.pcolormesh(\n",
    "        grid.x, grid.y, E.T / np.max(E), shading='auto', \n",
    "        vmin=-1.0, vmax=1.0, cmap='RdBu',\n",
    "    )\n",
    "fig.colorbar(m, width='1.25em')\n",
    "axs.format(xlabel='x', ylabel='y')\n",
    "axs[0].format(title=r'$E_x$ / max($E_x$)')\n",
    "axs[1].format(title=r'$E_y$ / max($E_y$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the value of the electric field at each particle position can be interpolated from the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex_int = grid.interpolate(Ex, bunch.positions)\n",
    "Ey_int = grid.interpolate(Ey, bunch.positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle mover "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do in this step is integrate the equations of motion. A common method is [leapfrog integration](https://en.wikipedia.org/wiki/Leapfrog_integration) in which the position and velocity are integrated out of phase as follows:\n",
    "\n",
    "$$ \n",
    "m \\left(\\frac{\\mathbf{v}_{i+1/2} - \\mathbf{v}_{i-1/2}}{\\Delta_t}\\right) = \\mathbf{F}(\\mathbf{x}_i),\n",
    "$${#eq-label}\n",
    "\n",
    "$$ \n",
    "\\frac{\\mathbf{x}_{i+1} - \\mathbf{x}_i}{\\Delta_t} = \\mathbf{v}_{i+1/2}\n",
    "$${#eq-label}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 9. Leapfrog integration. (Source: S. Lund.)](leapfrog.png){width=75%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different scheme must be used when velocity-dependent forces are present. This is a symplectic integrator, which means it conserves energy. It is also second-order accurate, meaning that its error is proportional to the square of the $\\Delta_t$. Finally, it is time-reversible. The only complication is that, because the velocity and position are out of phase, we need to push the velocity back one half-step before starting the simulation, and push it one half-step forward when taking a measurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "### Simulation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the tools to implement the simulation loop. While $s < s_{max}$ we: \n",
    "\n",
    "1. Compute the charge density on the grid.\n",
    "2. Find the electric potential on the grid.\n",
    "3. Interpolate the electric field at the particle positions.\n",
    "3. Update the particle positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first create a `History` class which stores the beam moments or phase space coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class History:\n",
    "    \"\"\"Class to store bunch data over time.\n",
    "    \n",
    "    Atributes\n",
    "    ---------\n",
    "    moments : list\n",
    "        Second-order bunch moments. Each element is ndarray of shape (10,).\n",
    "    coords : list\n",
    "        Bunch coordinate arrays. Each element is ndarray of shape (nparts, 4)\n",
    "    moment_positions, coord_positions : list\n",
    "        Positions corresponding to each element of `moments` or `coords`.\n",
    "    \"\"\"\n",
    "    def __init__(self, bunch, samples='all'):\n",
    "        self.X = bunch.X\n",
    "        self.moments, self.coords = [], []\n",
    "        self.moment_positions, self.coord_positions = [], []\n",
    "        if samples == 'all' or samples >= bunch.nparts:\n",
    "            self.idx = np.arange(bunch.nparts)\n",
    "        else:\n",
    "            self.idx = np.random.choice(bunch.nparts, samples, replace=False)\n",
    "        \n",
    "    def store_moments(self, s):\n",
    "        Sigma = np.cov(self.X.T)\n",
    "        self.moments.append(Sigma[np.triu_indices(4)])\n",
    "        self.moment_positions.append(s)\n",
    "        \n",
    "    def store_coords(self, s):\n",
    "        self.coords.append(np.copy(self.X[self.idx, :]))\n",
    "        self.coord_positions.append(s)\n",
    "        \n",
    "    def package(self):\n",
    "        self.moments = np.array(self.moments)\n",
    "        self.coords = np.array(self.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a `Simulation` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    \"\"\"Class to simulate the evolution of a charged particle bunch in free space.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    bunch : Bunch:\n",
    "        The bunch to track.\n",
    "    distance : float\n",
    "        Total tracking distance [m].\n",
    "    step_size : float\n",
    "        Distance between force calculations [m].\n",
    "    nsteps : float\n",
    "        Total number of steps = int(length / ds).\n",
    "    steps_performed : int\n",
    "        Number of steps performed so far.\n",
    "    s : float\n",
    "        Current bunch position.\n",
    "    history : History object\n",
    "        Object storing historic bunch data.\n",
    "    meas_every : dict\n",
    "        Dictionary with keys: 'moments' and 'coords'. Values correspond to the \n",
    "        number of simulations steps between storing these quantities. For\n",
    "        example, `meas_every = {'coords':4, 'moments':2}` will store the\n",
    "        moments every 4 steps and the moments every other step. Defaults to\n",
    "        storing only the initial and final positions.\n",
    "    samples : int\n",
    "        Number of bunch particles to store when measuring phase space\n",
    "        coordinates. Defaults to the entire coordinate array.\n",
    "    \"\"\"\n",
    "    def __init__(self, bunch, distance, step_size, grid_size, meas_every={}, \n",
    "                 samples='all'):\n",
    "        self.bunch = bunch\n",
    "        self.distance, self.step_size = distance, step_size \n",
    "        self.nsteps = int(distance / step_size)\n",
    "        self.grid = Grid(size=grid_size)\n",
    "        self.solver = PoissonSolver(self.grid)\n",
    "        self.fields = np.zeros((bunch.nparts, 2))\n",
    "        self.history = History(bunch, samples)  \n",
    "        self.s, self.steps_performed = 0.0, 0\n",
    "        self.meas_every = meas_every\n",
    "        self.meas_every.setdefault('moments', self.nsteps)\n",
    "        self.meas_every.setdefault('coords', self.nsteps)\n",
    "        self.sc_factor = bunch.perveance / bunch.nparts\n",
    "\n",
    "    def set_grid(self):\n",
    "        \"\"\"Set grid limits from bunch size.\"\"\"\n",
    "        self.bunch.compute_extremum()\n",
    "        self.grid.set_lims(self.bunch.xlim, self.bunch.ylim)\n",
    "        self.solver.set_grid(self.grid)\n",
    "        \n",
    "    def compute_electric_field(self):\n",
    "        \"\"\"Compute self-generated electric field.\"\"\"\n",
    "        self.set_grid()\n",
    "        rho = self.grid.distribute(self.bunch.positions)\n",
    "        phi = self.solver.get_potential(rho)\n",
    "        Ex, Ey = self.grid.gradient(-phi)\n",
    "        self.fields[:, 0] = self.grid.interpolate(Ex, self.bunch.positions)\n",
    "        self.fields[:, 1] = self.grid.interpolate(Ey, self.bunch.positions)\n",
    "                            \n",
    "    def kick(self, step_size):\n",
    "        \"\"\"Update particle slopes.\"\"\"\n",
    "        self.bunch.X[:, 1] += self.sc_factor * self.fields[:, 0] * step_size\n",
    "        self.bunch.X[:, 3] += self.sc_factor * self.fields[:, 1] * step_size\n",
    "        \n",
    "    def push(self, step_size):\n",
    "        \"\"\"Update particle positions.\"\"\"\n",
    "        self.bunch.X[:, 0] += self.bunch.X[:, 1] * step_size\n",
    "        self.bunch.X[:, 2] += self.bunch.X[:, 3] * step_size\n",
    "        \n",
    "    def store(self):\n",
    "        \"\"\"Store bunch data.\"\"\"\n",
    "        store_moments = self.steps_performed % self.meas_every['moments'] == 0\n",
    "        store_coords = self.steps_performed % self.meas_every['coords'] == 0\n",
    "        if not (store_moments or store_coords):\n",
    "            return\n",
    "        Xp = np.copy(self.bunch.X[:, [1, 3]])\n",
    "        self.kick(+0.5 * self.step_size) # sync positions/slopes\n",
    "        if store_moments:\n",
    "            self.history.store_moments(self.s)\n",
    "        if store_coords:\n",
    "            self.history.store_coords(self.s)\n",
    "        self.bunch.X[:, [1, 3]] = Xp\n",
    "        \n",
    "    def run(self, meas_every={}):\n",
    "        \"\"\"Run the simulation.\"\"\"\n",
    "        self.store()\n",
    "        self.compute_electric_field()\n",
    "        self.kick(-0.5 * self.step_size) # desync positions/slopes\n",
    "        for i in trange(self.nsteps):\n",
    "            self.compute_electric_field()\n",
    "            self.kick(self.step_size)\n",
    "            self.push(self.step_size)\n",
    "            self.s += self.step_size\n",
    "            self.steps_performed += 1\n",
    "            self.store()\n",
    "        self.history.package()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: freely expanding Vlasov equilibrium distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some way of checking our method's accuracy. Luckily there is an analytic benchmark available: the Kapchinskij-Vladimirskij (KV) distribution. Without going into any detail, the beam projects to a uniform density ellipse in the $x$-$y$ plane, and the space charge forces produced within this ellipse are *linear* (in general space charge forces are nonlinear). If we plug the KV distribution into the Vlasov equation, it can be seen that these forces will remain linear for all time if the external focusing forces are also linear. As a consequence, a set of self-consistent differential equations describing the evolution of the ellipse boundary can be written down. If we consider the beam to be an upright ellipse with semi-axis $a$ along the $x$ axis and $b$ along the $y$ axis, then without external fields the equations read:\n",
    "\n",
    "$$ a'' = \\frac{2Q}{a + b} + \\frac{\\varepsilon_x}{a^3}, $$\n",
    "$$ b'' = \\frac{2Q}{a + b} + \\frac{\\varepsilon_y}{b^3}. \\tag{18}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are known as the *KV envelope equations* or simply *envelope equations*. $Q$, called the *perveance*, is a dimensionless number which is proportional to the beam intensity but reduced by the beam energy. We can think of this constant as a measure of the space charge strength. The $\\varepsilon_x$ and $\\varepsilon_y$ terms are called the *emittances* and determine the area occupied by the beam in $x$-$x'$ and $y$-$y'$ phase space. For example, a beam with all particles sitting perfectly still in the $x$-$y$ plane has no emittance, but a beam which is instead spreading out has a nonzero emittance. These emittances will also be conserved for the KV distribution. The following function integrates the envelope equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_env(X, positions, perveance=0.0):\n",
    "    \"\"\"Track beam moments (assuming KV distribution) through free space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (nparts, 4)\n",
    "        Transverse bunch coordinate array.\n",
    "    positions : list\n",
    "        List of positions at which to evaluate the equations.\n",
    "    perveance : float\n",
    "        The dimensionless space charge perveance.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray, shape (len(positions), 4)\n",
    "        Each row gives [a, a', b, b'], where a and b are the beam\n",
    "        radii in the x and y dimension, respectively.\n",
    "    \"\"\"\n",
    "    Sigma = np.cov(X.T)\n",
    "    a, b = np.sqrt(Sigma[0, 0]), np.sqrt(Sigma[2, 2])\n",
    "    ap, bp = Sigma[0, 1] / a, Sigma[2, 3] / b\n",
    "    epsx = np.sqrt(np.linalg.det(Sigma[:2, :2]))\n",
    "    epsy = np.sqrt(np.linalg.det(Sigma[2:, 2:]))\n",
    "\n",
    "    def derivs(env, s):\n",
    "        a, ap, b, bp = env\n",
    "        envp = np.zeros(4)\n",
    "        envp[0], envp[2] = ap, bp\n",
    "        envp[1] = 0.5 * perveance/(a + b) + epsx**2 / a**3\n",
    "        envp[3] = 0.5 * perveance/(a + b) + epsy**2 / b**3\n",
    "        return envp\n",
    "    \n",
    "    return odeint(derivs, [a, ap, b, bp], positions, atol=1e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some care must be taken in the choice of simulation parameters; we need a fine enough grid to resolve the hard edge of the beam and enough macroparticles per grid cell to collect good statistics. I chose what I thought was reasonable: 128,000 macroparticles, a step size of 2.5 cm, and a $128 \\times 128$ grid. Let's create and track four identical KV distributions, each with a different intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunch parameters\n",
    "nparts = 128000\n",
    "bunch_length = 250.0 # [m]\n",
    "intensities = [0.0, 10.0e14, 20.0e14, 40.0e14]\n",
    "\n",
    "# Simulation parameters\n",
    "distance = 10.0 # [m]\n",
    "step_size = 0.025 # [m]\n",
    "grid_size = (128, 128)\n",
    "samples = 10000\n",
    "meas_every = {\n",
    "    'moments': int(0.1 * distance / step_size), \n",
    "    'coords': 4\n",
    "}\n",
    "\n",
    "# Create KV bunch in normalized coordinates (surface of 4D unit sphere)\n",
    "X = np.random.normal(size=(nparts, 4))\n",
    "X = np.apply_along_axis(lambda row: row / np.linalg.norm(row), 1, X)\n",
    "\n",
    "# Scale by emittance\n",
    "eps_x, eps_y = 10e-6, 10e-6\n",
    "A = 2 * np.sqrt(np.diag([eps_x, eps_x, eps_y, eps_y]))\n",
    "X = np.apply_along_axis(lambda row: np.matmul(A, row), 1, X)\n",
    "\n",
    "# Scale beam size and divergence relative to emittance\n",
    "alpha_x = alpha_y = 0.0\n",
    "beta_x = beta_y = 20.0\n",
    "V = np.zeros((4, 4))\n",
    "V[:2, :2] = np.sqrt(1.0 / beta_x)* np.array([[beta_x, 0.0], [alpha_x, 1.0]])\n",
    "V[2:, 2:] = np.sqrt(1.0 / beta_y)* np.array([[beta_y, 0.0], [alpha_y, 1.0]])\n",
    "X = np.apply_along_axis(lambda row: np.matmul(V, row), 1, X)\n",
    "\n",
    "# Create and track bunches\n",
    "sims = []\n",
    "for intensity in intensities:\n",
    "    bunch = Bunch(intensity, bunch_length)\n",
    "    bunch.fill(np.copy(X))\n",
    "    sim = Simulation(bunch, distance, step_size, grid_size, meas_every=meas_every, samples=samples)\n",
    "    sim.run()\n",
    "    sims.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| fig-cap: \"Fig. 10. Benchmark: free expansion of a KV distribution. Solid lines show the exact results obtained by integrating the KV envelop equations. Dots show the PIC results.\"\n",
    "bunch_positions = sims[0].history.moment_positions\n",
    "env_positions = np.linspace(0, distance, 400)\n",
    "rms_sizes_lists = {'bunch':[], 'env':[]}\n",
    "for sim in sims:\n",
    "    rms_sizes_lists['bunch'].append(np.sqrt(sim.history.moments[:, [0, 7]]))\n",
    "    rms_sizes_lists['env'].append(track_env(X, env_positions, sim.bunch.perveance)[:, [0, 2]])\n",
    "\n",
    "fig, axs = pplt.subplots(ncols=2, figsize=(7.25, 2.75), spany=False)\n",
    "alphas = np.linspace(0.4, 1.0, 4)\n",
    "cycle = pplt.Cycle(pplt.Colormap('blues', left=0.3))\n",
    "colors = cycle.by_key()['color'][::3]\n",
    "for key, rms_sizes_list in rms_sizes_lists.items():\n",
    "    for rms_sizes, alpha, color in zip(rms_sizes_list, alphas, colors):\n",
    "        for i, ax in enumerate(axs):\n",
    "            if key == 'env':\n",
    "                ax.plot(env_positions, 1000.0 * rms_sizes[:, i], c=color, alpha=alpha)\n",
    "            elif key == 'bunch':\n",
    "                ax.scatter(bunch_positions, 1000.0 * rms_sizes[:, i], s=8, c=color, zorder=99)\n",
    "            \n",
    "lines = [Line2D([0], [0], color=color) for color in colors]\n",
    "axs[0].legend(lines, [f'$I/I_0$ = {i}' for i in (0, 1, 2, 4)], ncols=1, fontsize=7)\n",
    "axs[0].set_title('Horizontal')\n",
    "axs[1].set_title('Vertical')\n",
    "axs.format(xlim=(-0.5, 10.5), ylabel='RMS beam size [$mm$]', xlabel='Position [m]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the horizontal and vertical beam size over time for each of the four chosen beam intensities. The solid lines are the result of integrating the envelope equations, while the dots are the result of the PIC calculation. Notice that the beam expands on its own due to the nonzero emittance and that the effect of space charge is to increase the expansion rate. It seems to be quite accurate over this distance, and the runtime is acceptable for my purposes. Here is the evolution of 10,000 randomly sampled macroparicles compared with the KV envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "# Get coordinates\n",
    "coords_list = [sim.history.coords for sim in sims]\n",
    "positions = sims[0].history.coord_positions\n",
    "umax = 1.25 * max([np.max(np.max(coords, axis=1)[:, [0, 2]]) for coords in coords_list])\n",
    "umax = umax * 1000.0\n",
    "\n",
    "# Create figure\n",
    "fig, axs = pplt.subplots(nrows=2, ncols=2, figwidth=5.0)\n",
    "axs.format(\n",
    "    xspineloc='bottom', yspineloc='left',\n",
    "    xlim=(-umax, umax), ylim=(-umax, umax),\n",
    "    xlabel='x [mm]', ylabel='y [mm]'\n",
    ")\n",
    "axs[1].legend([Line2D([0], [0], color='red6')], ['KV envelope'], frameon=False, loc=(0.5, 0.95))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.annotate(f'$I/I_0$ = {i}', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "plt.close()\n",
    "\n",
    "# Create lines\n",
    "lines = []\n",
    "for ax in axs:\n",
    "    line, = ax.plot([], [], ms=1.25, c='black', marker='.', lw=0, mew=0, fillstyle='full')\n",
    "    lines.append(line)\n",
    "        \n",
    "def update(t):\n",
    "    for ax, coords, line, rms_sizes_list in zip(axs, coords_list, lines, rms_sizes_lists['env']):\n",
    "        line.set_data(1000.0 * coords[t, :, 0], 1000.0 * coords[t, :, 2])\n",
    "        rms_sizes_list = rms_sizes_list[::4]\n",
    "        a, b = 1000.0 * rms_sizes_list[t]\n",
    "        ax.patches = []\n",
    "        ax.add_patch(Ellipse((0.0, 0.0), 4.0 * a, 4.0 * b, color='red6', fill=False, zorder=100, lw=1))\n",
    "    axs[0].set_title('s = {:.2f} m'.format(positions[t]))\n",
    "        \n",
    "frames = len(coords_list[0]) - 1\n",
    "anim = animation.FuncAnimation(fig, update, frames=frames, interval=1000.0 / 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "anim.save('./_output_anim.gif', dpi=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 11. Evolution of 10,000 macroparticles (black) and KV envelope (red) during free-expansion.](./_output_anim.gif){width=70%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post implemented an electrostatic PIC solver in Python. I learned quite a bit from doing this and was happy to see my calculations agree with the theoretical benchmark. One extension of this code would be to consider the velocity-dependent force from magnetic fields. It would also be straightforward to extend the code to 3D. Finally, all the methods used here are applicable to gravitational simulations. Here are some helpful references:\n",
    "\n",
    "* [USPAS course](https://people.nscl.msu.edu/~lund/uspas/sbp_2018/)\n",
    "* [Hockney & Eastwood](https://www.amazon.com/Computer-Simulation-Using-Particles-Hockney/dp/0852743920)\n",
    "* [Birdsall & Langdon](https://www.amazon.com/Plasma-Physics-via-Computer-Simulation/dp/0750310251)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
